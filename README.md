🧠 Overview
========
A full-stack machine learning pipeline built to predict user survival rates using real-time data pipelines based on famous Titanic Dataset, MLOps orchestration, and observability tooling. Designed for high scalability and production-grade insights, this project showcases my ability to integrate ML models into robust data infrastructure.

⚙️ Key Features
================

1) ETL Pipeline with Astro + Airflow
Modular and DAG-based pipeline that ingests, processes, and pushes data into SQL databases for downstream tasks.

2) Prediction Engine
Trained ML model to classify user survival likelihood based on behavioral data.

3) Redis Integration
Fast caching and retrieval of intermediate results and prediction outcomes.

4) Monitoring with Prometheus + Grafana
Set up real-time monitoring dashboards to track pipeline performance, latency, and uptime.

5) SQL for Data Modeling & Storage
Cleaned and structured the dataset in SQL for better querying and analytics.

📊 Tech Stack
===========================

Astro · Apache Airflow · Redis · SQL · Prometheus · Grafana · Pandas · Scikit-learn

💡 What I Learned
=================================

1) Setting up a scalable ML pipeline using Airflow on Astro

2) Real-time monitoring and alerting using Prometheus and Grafana

3) Building modular ETL jobs and managing dependencies efficiently
